{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/UEPP40/PUM/blob/gamszej/system_rekomendacyjny.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rgodiPga79kj"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from mlxtend.frequent_patterns import apriori, association_rules\n",
        "from mlxtend.preprocessing import TransactionEncoder\n",
        "from scipy.sparse import csr_matrix\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from scipy.sparse import csr_matrix\n",
        "from datetime import datetime\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataGrocery = pd.read_csv('GroceryStoreDataSet.csv', names=[\"products\"])\n",
        "dataGrocery.head(10)"
      ],
      "metadata": {
        "id": "mxK3tayA8H7s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataGroceryStructured = dataGrocery['products'].apply(lambda x: x.split(','))\n",
        "uniqueItems = set([item for sublist in dataGroceryStructured for item in sublist])\n",
        "sorted(uniqueItems)\n",
        "\n",
        "dataGrocery['products'] = dataGrocery['products'].str.replace('COCK', 'COKE').str.replace('SUGER', 'SUGAR')\n",
        "dataGroceryStructured = dataGrocery['products'].apply(lambda x: x.split(','))\n",
        "\n",
        "transaction_encoder = TransactionEncoder()\n",
        "dataGroceryEncoded = transaction_encoder.fit(dataGroceryStructured).transform(dataGroceryStructured)\n",
        "dataGroceryEncoded = pd.DataFrame(dataGroceryEncoded, columns=transaction_encoder.columns_).astype(int)"
      ],
      "metadata": {
        "id": "yIq_t46b8R-2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Para produktów o największym lift i  największej ufności\n",
        "\n",
        "frequent_itemsets = apriori(dataGroceryEncoded, min_support=0.15, use_colnames=True)\n",
        "\n",
        "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.1)\n",
        "max_confidence_rule = rules[rules['confidence'] == rules['confidence'].max()].head(1)\n",
        "\n",
        "rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=0.1)\n",
        "max_lift_rule = rules[rules['lift'] == rules['lift'].max()].head(1)"
      ],
      "metadata": {
        "id": "uXvRTRLU87Nv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratings = pd.read_csv('https://s3-us-west-2.amazonaws.com/recommender-tutorial/ratings.csv')\n",
        "movies = pd.read_csv('https://s3-us-west-2.amazonaws.com/recommender-tutorial/movies.csv')"
      ],
      "metadata": {
        "id": "yYff591t9Q5l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Missing values in ratings:\\n\", ratings.isnull().sum())"
      ],
      "metadata": {
        "id": "CAqUPclq9ybw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Missing values in movies:\\n\", movies.isnull().sum())"
      ],
      "metadata": {
        "id": "HQbc2BWt9y7N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Ratings: \", ratings['rating'].nunique(), sorted(ratings['rating'].unique()))\n",
        "ratings['rating'].value_counts()"
      ],
      "metadata": {
        "id": "ooDA_UGd91S8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Amount of ratings: \", ratings.shape[0])\n",
        "print(\"Movies creted: \", movies['movieId'].nunique(),\", Unique Titles\", movies['title'].nunique())\n",
        "print(\"Movies revied: \", movies['movieId'].nunique())\n",
        "print(\"Amount of users: \", ratings['userId'].nunique(),\", Highest Id\", ratings['userId'].max())\n",
        "print(\"Average amount of ratings per user: \", round(ratings.shape[0]/ratings['userId'].nunique(),2))\n",
        "print(\"Average amount of ratings per movie: \", round(ratings.shape[0]/ratings['movieId'].nunique(),2))"
      ],
      "metadata": {
        "id": "Q-gHTXoT95Bu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "titles = list(movies['title'])\n",
        "duplicates = set([x for x in titles if titles.count(x) > 1])\n",
        "\n",
        "print(\"Duplicated titles:\")\n",
        "for duplicate in duplicates:\n",
        "  print(\"  -\",duplicate)\n",
        "\n",
        "movies[movies['title'].isin(duplicates)]"
      ],
      "metadata": {
        "id": "YGk4-g8C98AE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movie_titles_dict = dict(zip(movies['movieId'], movies['title']))"
      ],
      "metadata": {
        "id": "g_XQ6US9-E7s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "av = ratings.shape[0]/ratings['movieId'].nunique()\n",
        "avargeOfAll = ratings['rating'].sum()/ratings.shape[0]\n",
        "print(\"Average rating: \",av, \", Average rating of all movies: \",avargeOfAll)"
      ],
      "metadata": {
        "id": "ukJcbTDW-J_7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bayesian_avg(ratings):\n",
        "    bayesian_avg = (av * avargeOfAll + ratings.sum()) / (av + ratings.count())\n",
        "    return bayesian_avg\n",
        "\n",
        "bayesian_avg_ratings = ratings.groupby('movieId')['rating'].agg(bayesian_avg).reset_index()\n",
        "bayesian_avg_ratings.columns = ['movieId', 'bayesian_avg']\n",
        "movie_stats = pd.merge(movies, bayesian_avg_ratings, on='movieId')\n",
        "\n",
        "print(movie_stats.head())"
      ],
      "metadata": {
        "id": "VOlcktCz-ZTh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_sparse(df):\n",
        "  userId = df['userId'].nunique()\n",
        "  movieId = df['movieId'].nunique()\n",
        "  user_mapper = dict(zip(np.unique(df[\"userId\"]), list(range(userId))))\n",
        "  movie_mapper = dict(zip(np.unique(df[\"movieId\"]), list(range(movieId))))\n",
        "  user_inv_mapper = dict(zip(list(range(userId)), np.unique(df[\"userId\"])))\n",
        "  movie_inv_mapper = dict(zip(list(range(movieId)), np.unique(df[\"movieId\"])))\n",
        "  user_index = [user_mapper[i] for i in df['userId']]\n",
        "  item_index = [movie_mapper[i] for i in df['movieId']]\n",
        "  X = csr_matrix((df[\"rating\"], (user_index, item_index)), shape=(userId,movieId))\n",
        "  return X, user_mapper, movie_mapper, user_inv_mapper, movie_inv_mapper\n",
        "\n",
        "  X, user_mapper, movie_mapper, user_inv_mapper, movie_inv_mapper = create_sparse(ratings)"
      ],
      "metadata": {
        "id": "TQEikOtO-g-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_similar_movies(movie_id, X, movie_mapper, movie_inv_mapper, k, metric='cosine'):\n",
        "    X = X.T\n",
        "    neighbour_ids = []\n",
        "    movie_ind = movie_mapper[movie_id]\n",
        "    movie_vec = X[movie_ind]\n",
        "    if isinstance(movie_vec, (np.ndarray)):\n",
        "        movie_vec = movie_vec.reshape(1,-1)\n",
        "    kNN = NearestNeighbors(n_neighbors=k+1, algorithm=\"brute\", metric=metric)\n",
        "    kNN.fit(X)\n",
        "    neighbour = kNN.kneighbors(movie_vec, return_distance=False)\n",
        "    for i in range(0,k):\n",
        "        n = neighbour.item(i)\n",
        "        neighbour_ids.append(movie_inv_mapper[n])\n",
        "    neighbour_ids.pop(0)\n",
        "    return neighbour_ids"
      ],
      "metadata": {
        "id": "3EgGes7R-vjg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_total = X.shape[0]*X.shape[1]\n",
        "n_ratings = X.nnz\n",
        "sparsity = n_ratings/n_total\n",
        "sparsity_p = round(sparsity*100,2)\n",
        "print(f\"Matrix sparsity: {sparsity_p}%\")\n",
        "n_ratings_per_user = X.getnnz(axis=1)"
      ],
      "metadata": {
        "id": "UGue5gKB-yqU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_ratings_per_user = X.getnnz(axis=1)\n",
        "print(\"Amount of ratings per user:\", n_ratings_per_user)"
      ],
      "metadata": {
        "id": "BsnW_CRo_MNv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "toyStoryID = movies[movies['title'].str.contains('Toy Story \\(')]['movieId'][0]\n",
        "similarMovies = find_similar_movies(toyStoryID, X, movie_mapper, movie_inv_mapper, k=10, metric='cosine')\n",
        "print(f\"Most similar movies (Id):  {toyStoryID}: {similarMovies}\")\n",
        "print(f\"\\nMost similar movies (Title):  {list(movies[movies['movieId']==toyStoryID]['title'])}:\")\n",
        "movies[movies['movieId'].isin(similarMovies)]['title']"
      ],
      "metadata": {
        "id": "qE1zrUOa_O3a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "toyStoryID = movies[movies['title'].str.contains('Toy Story \\(')]['movieId'][0]\n",
        "toyStoryID"
      ],
      "metadata": {
        "id": "i-7-t29g_SUS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movies['genres'] = movies['genres'].str.lower()\n",
        "movies['year'] = movies['title'].str.extract(r'\\((\\d{4})\\)', expand=False)"
      ],
      "metadata": {
        "id": "tpotQe8s_cBt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "genreLists = list(movies['genres'].apply(lambda x: x.lower().split('|')))\n",
        "genreList = []\n",
        "\n",
        "for genres in genreLists:\n",
        "  genreLists.extend(genres)\n",
        "\n",
        "print(\"Set of unique genres (lowercase):\", set(genreList))\n",
        "genre_df = pd.DataFrame(genreList)\n",
        "genre_df.value_counts()"
      ],
      "metadata": {
        "id": "uaI9Z932_ena"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Podaj liczbę filmów dla dzieci\n",
        "children_movies_count = movies(\"Number of children movies:\", children_movies_count)\n",
        "\n",
        "ratings['rating_year'] = pd.to_datetime(ratings['timestamp'], unit='s').dt.year"
      ],
      "metadata": {
        "id": "lWnIqKw7_pyt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Pokaż rozkład ocen filmów z 1995\n",
        "import matplotlib.pyplot as plt\n",
        "ratingsJoin = ratings.merge(movies, on='movieId', how='inner')\n",
        "ratings_1995 = ratingsJoin[ratingsJoin['year'] == '1995']\n",
        "ratings_distribution_1995 = ratings_1995['rating'].value_counts().sort_index()\n",
        "print(\"Distribution of 1995 film ratings:\")\n",
        "print(ratings_distribution_1995)\n",
        "plt.figure(figsize=(10, 6))\n",
        "ratings_distribution_1995.plot(kind='bar')\n",
        "plt.title('Distribution of 1995 film ratings')\n",
        "plt.xlabel('Rate')\n",
        "plt.ylabel('Number of appearances')\n",
        "plt.xticks(rotation=0)\n",
        "plt.grid(axis='y')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pFj1ZU0L_9PP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Podaj średnią ocen wszystkich filmów akcji oraz 3 filmy najwyżej oceniane\n",
        "actionMovies = ratingsJoin[ratingsJoin['genres'].str.contains('action', case=False)]\n",
        "\n",
        "average_rating_action = actionMovies['rating'].mean()\n",
        "print(f\"Average ratings for action movies: {average_rating_action}\")\n",
        "\n",
        "top_three = actionMovies.groupby('title')['rating'].mean().sort_values(ascending=False).head(3)\n",
        "print(f\"\\nThe three highest rated action films: {top_three}\")"
      ],
      "metadata": {
        "id": "i3jIescXALLh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install surprise"
      ],
      "metadata": {
        "id": "wfBunKJfBMm_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from surprise.model_selection import cross_validate, GridSearchCV\n",
        "from surprise.prediction_algorithms import SVD, KNNBasic, KNNBaseline\n",
        "from surprise import Dataset\n",
        "from surprise import Reader\n",
        "from surprise import accuracy, Dataset, SVD\n",
        "from surprise.model_selection import train_test_split\n",
        "\n",
        "min_rating = ratings.rating.min()\n",
        "max_rating = ratings.rating.max()\n",
        "reader = Reader(rating_scale=(min_rating, max_rating))\n",
        "data = Dataset.load_from_df(ratings[['userId','movieId' , 'rating']], reader)\n",
        "trainset, testset = train_test_split(data, test_size = 0.25)"
      ],
      "metadata": {
        "id": "6w0kJfS7Ar6D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#svd\n",
        "start_time_svd_train = time.time()\n",
        "algo = SVD()\n",
        "algo.fit(trainset)\n",
        "predictions = algo.test(testset)\n",
        "accuracy.rmse(predictions)\n",
        "end_time_svd_train = time.time()"
      ],
      "metadata": {
        "id": "QE6unftcBNSV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {\n",
        "    'n_factors': [1,2,5,10, 50]\n",
        "}\n",
        "\n",
        "start_time_svd = time.time()\n",
        "gsSVD = GridSearchCV(SVD, param_grid, measures=['rmse'], cv=5, n_jobs=-1)\n",
        "gsSVD.fit(data)\n",
        "end_time_svd = time.time()\n",
        "gsSVD.best_params\n",
        "\n",
        "cross_validate(SVD(), data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
      ],
      "metadata": {
        "id": "Fev-wmOlBQOs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#knn basic\n",
        "lgo = KNNBasic()\n",
        "start_time_knn_train = time.time()\n",
        "algo.fit(trainset)\n",
        "predictions = algo.test(testset)\n",
        "accuracy.rmse(predictions)\n",
        "end_time_knn_train = time.time()"
      ],
      "metadata": {
        "id": "CVv1gf3ZBY1N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {\n",
        "    'k': [1, 2, 5, 10, 20, 30, 40, 50]\n",
        "}\n",
        "start_time_knn = time.time()\n",
        "\n",
        "gsKNN = GridSearchCV(KNNBasic, param_grid, measures=['rmse'], cv=5, n_jobs=-1)\n",
        "gsKNN.fit(data)\n",
        "end_time_knn = time.time()\n",
        "gsKNN.best_params\n",
        "\n",
        "cross_validate(KNNBasic(), data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
      ],
      "metadata": {
        "id": "OW24uMJKBdOy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#knn baseline\n",
        "algo = KNNBaseline()\n",
        "algo.fit(trainset)\n",
        "predictions = algo.test(testset)\n",
        "accuracy.rmse(predictions)"
      ],
      "metadata": {
        "id": "vqlXqNTiBlfb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#porównanie\n",
        "bestKNN = gs_knn.best_estimator['rmse']\n",
        "bestSVD = gs_svd.best_estimator['rmse']\n",
        "\n",
        "start_time_knn_cross = time.time()\n",
        "resultsKNN = cross_validate(bestKNN, data, measures=['rmse'], cv=5, verbose=True)\n",
        "end_time_knn_cross = time.time()\n",
        "\n",
        "start_time_svd_cross = time.time()\n",
        "resultsSVD = cross_validate(bestSVD, data, measures=['rmse'], cv=5, verbose=True)\n",
        "end_time_svd_cross = time.time()\n",
        "\n",
        "print(f\"\\nBest KNN RMSE: {gs_knn.best_score['rmse']}\")\n",
        "print(f\"Best SVD RMSE: {gs_svd.best_score['rmse']}\")\n",
        "print(f\"\\nBest KNN Parameters: {gs_knn.best_params['rmse']}\")\n",
        "print(f\"Best SVD Parameters: {gs_svd.best_params['rmse']}\")\n",
        "print(f\"\\nHyperparameters KNN Training Time: {end_time_knn - start_time_knn} seconds\")\n",
        "print(f\"Hyperparameters SVD Training Time: {end_time_svd - start_time_svd} seconds\")\n",
        "print(f\"\\nCros KNN Training Time: {end_time_knn - start_time_knn} seconds\")\n",
        "print(f\"Cros SVD Training Time: {end_time_svd_cross - start_time_svd_cross} seconds\")\n",
        "print(f\"\\nTrain SVD Training Time: {end_time_svd_train - start_time_svd_train} seconds\")\n",
        "print(f\"Train KNN Training Time: {end_time_knn_train - start_time_knn_train} seconds\")\n",
        "print(f\"\\nKNN Cross-validation Results: {resultsKNN}\")\n",
        "print(f\"SVD Cross-validation Results: {resultsSVD}\")"
      ],
      "metadata": {
        "id": "DIAd6AHDBqUN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}