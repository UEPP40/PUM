{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/UEPP40/PUM/blob/friska_test/2505moviesPUM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "ratings = pd.read_csv('https://s3-us-west-2.amazonaws.com/recommender-tutorial/ratings.csv')\n",
        "movies = pd.read_csv('https://s3-us-west-2.amazonaws.com/recommender-tutorial/movies.csv')\n",
        "\n",
        "\n",
        "totalratings = ratings.shape[0]\n",
        "totalmovies = movies.shape[0]\n",
        "\n",
        "totalusers = ratings['userId'].nunique()\n",
        "\n",
        "avgratings_per_user = totalratings / totalusers\n",
        "\n",
        "avgratings_per_movie = totalratings / totalmovies\n",
        "\n",
        "\n",
        "ratingsdistribution = ratings['rating'].value_counts().sort_index()\n",
        "\n",
        "\n",
        "print(\"All ratings count:\", totalratings)\n",
        "print(\"All movies count:\", totalmovies)\n",
        "print(\"All users count\", totalusers)\n",
        "print(\"Average rating per user:\", avgratings_per_user)\n",
        "print(\"Average rating per movie:\", avgratings_per_movie)\n",
        "print(\"\\nRatings distribution:\")\n",
        "print(ratingsdistribution)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Rfrduhc0TBJ",
        "outputId": "4859259e-b5e7-4e80-f007-766b091d3ea4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All ratings count: 100836\n",
            "All movies count: 9742\n",
            "All users count 610\n",
            "Average rating per user: 165.30491803278687\n",
            "Average rating per movie: 10.350646684459043\n",
            "\n",
            "Ratings distribution:\n",
            "rating\n",
            "0.5     1370\n",
            "1.0     2811\n",
            "1.5     1791\n",
            "2.0     7551\n",
            "2.5     5550\n",
            "3.0    20047\n",
            "3.5    13136\n",
            "4.0    26818\n",
            "4.5     8551\n",
            "5.0    13211\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "movie_titles = dict(zip(movies['movieId'], movies['title']))\n",
        "m = ratings.groupby('movieId')['rating'].agg(['count', 'mean'])\n",
        "m = m['count'].mean()\n",
        "C = ratings['rating'].mean()\n",
        "\n",
        "\n",
        "def bayesian_avg(ratings):\n",
        "    bayesian_avg = (C * m + ratings.sum()) / (C + ratings.count())\n",
        "    return bayesian_avg\n",
        "\n",
        "bayesian_avgratings = ratings.groupby('movieId')['rating'].agg(bayesian_avg).reset_index()\n",
        "bayesian_avgratings.columns = ['movieId', 'bayesian_avg']\n",
        "\n",
        "movie_stats = movies.merge(bayesian_avgratings, on='movieId')\n",
        "\n",
        "print(movie_stats.head())"
      ],
      "metadata": {
        "id": "dL2QO0Nc7s4g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e8c0374-f5d1-4218-ac07-061ae57d13b1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   movieId                               title  \\\n",
            "0        1                    Toy Story (1995)   \n",
            "1        2                      Jumanji (1995)   \n",
            "2        3             Grumpier Old Men (1995)   \n",
            "3        4            Waiting to Exhale (1995)   \n",
            "4        5  Father of the Bride Part II (1995)   \n",
            "\n",
            "                                        genres  bayesian_avg  \n",
            "0  Adventure|Animation|Children|Comedy|Fantasy      4.024276  \n",
            "1                   Adventure|Children|Fantasy      3.645857  \n",
            "2                               Comedy|Romance      3.708193  \n",
            "3                         Comedy|Drama|Romance      5.028823  \n",
            "4                                       Comedy      3.558189  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "ratings = pd.read_csv('https://s3-us-west-2.amazonaws.com/recommender-tutorial/ratings.csv')\n",
        "movies = pd.read_csv('https://s3-us-west-2.amazonaws.com/recommender-tutorial/movies.csv')\n",
        "totalmovies = movies.shape[0]\n",
        "totalusers = ratings['userId'].nunique()\n",
        "totalratings = ratings.shape[0]\n",
        "\n",
        "avgratings_per_user = totalratings / totalusers\n",
        "\n",
        "avgratings_per_movie = totalratings / totalmovies\n",
        "\n",
        "\n",
        "ratings_distribution = ratings['rating'].value_counts().sort_index()\n",
        "\n",
        "print(\"All ratings count:\", totalratings)\n",
        "print(\"All movies count:\", totalmovies)\n",
        "print(\"All users count\", totalusers)\n",
        "print(\"Average rating per user:\", avgratings_per_user)\n",
        "print(\"Average rating per movie:\", avgratings_per_movie)\n",
        "print(\"\\nRatings distribution:\")\n",
        "print(ratingsdistribution)\n",
        "movie_titles = dict(zip(movies['movieId'], movies['title']))\n",
        "\n",
        "C = ratings['rating'].mean()\n",
        "m = ratings.groupby('movieId')['rating'].agg(['count', 'mean'])\n",
        "m = m['count'].mean()\n",
        "\n",
        "\n",
        "def bayesian_avg(ratings):\n",
        "    bayesian_avg = (C * m + ratings.sum()) / (C + ratings.count())\n",
        "    return bayesian_avg\n",
        "\n",
        "\n",
        "bayesian_avg_ratings = ratings.groupby('movieId')['rating'].agg(bayesian_avg).reset_index()\n",
        "bayesian_avg_ratings.columns = ['movieId', 'bayesian_avg']\n",
        "\n",
        "\n",
        "movie_stats = movies.merge(bayesian_avg_ratings, on='movieId')\n",
        "\n",
        "\n",
        "print(movie_stats.head())\n",
        "\n",
        "def create_sparse(df):\n",
        "    M = df['userId'].nunique()\n",
        "    N = df['movieId'].nunique()\n",
        "    user_mapper = dict(zip(np.unique(df[\"userId\"]), list(range(M))))\n",
        "    movie_mapper = dict(zip(np.unique(df[\"movieId\"]), list(range(N))))\n",
        "    user_inv_mapper = dict(zip(list(range(M)), np.unique(df[\"userId\"])))\n",
        "    movie_inv_mapper = dict(zip(list(range(N)), np.unique(df[\"movieId\"])))\n",
        "    user_index = [user_mapper[i] for i in df['userId']]\n",
        "    item_index = [movie_mapper[i] for i in df['movieId']]\n",
        "    X = csr_matrix((df[\"rating\"], (user_index, item_index)), shape=(M,N))\n",
        "    return X, user_mapper, movie_mapper, user_inv_mapper, movie_inv_mapper\n",
        "\n",
        "X, user_mapper, movie_mapper, user_inv_mapper, movie_inv_mapper = create_sparse(ratings)\n",
        "\n",
        "n_total = X.shape[0] * X.shape[1]\n",
        "n_ratings = X.nnz\n",
        "sparsity = n_ratings / n_total\n",
        "sparsity_p = round(sparsity * 100, 2)\n",
        "\n",
        "print(f\"Matrix sparsity: {sparsity_p}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TO6f6-OJ7wyd",
        "outputId": "5d6d65d4-1b06-42e3-80f8-0957fe6f0033"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All ratings count: 100836\n",
            "All movies count: 9742\n",
            "All users count 610\n",
            "Average rating per user: 165.30491803278687\n",
            "Average rating per movie: 10.350646684459043\n",
            "\n",
            "Ratings distribution:\n",
            "rating\n",
            "0.5     1370\n",
            "1.0     2811\n",
            "1.5     1791\n",
            "2.0     7551\n",
            "2.5     5550\n",
            "3.0    20047\n",
            "3.5    13136\n",
            "4.0    26818\n",
            "4.5     8551\n",
            "5.0    13211\n",
            "Name: count, dtype: int64\n",
            "   movieId                               title  \\\n",
            "0        1                    Toy Story (1995)   \n",
            "1        2                      Jumanji (1995)   \n",
            "2        3             Grumpier Old Men (1995)   \n",
            "3        4            Waiting to Exhale (1995)   \n",
            "4        5  Father of the Bride Part II (1995)   \n",
            "\n",
            "                                        genres  bayesian_avg  \n",
            "0  Adventure|Animation|Children|Comedy|Fantasy      4.024276  \n",
            "1                   Adventure|Children|Fantasy      3.645857  \n",
            "2                               Comedy|Romance      3.708193  \n",
            "3                         Comedy|Drama|Romance      5.028823  \n",
            "4                                       Comedy      3.558189  \n",
            "Matrix sparsity: 1.7%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import NearestNeighbors\n",
        "import numpy as np\n",
        "\n",
        "def find_similar_movies(movie_id, X, movie_mapper, movie_inv_mapper, k, metric='cosine'):\n",
        "    X = X.T\n",
        "    neighbour_ids = []\n",
        "    movie_ind = movie_mapper[movie_id]\n",
        "    movie_vec = X[movie_ind]\n",
        "    if isinstance(movie_vec, (np.ndarray)):\n",
        "        movie_vec = movie_vec.reshape(1, -1)\n",
        "    kNN = NearestNeighbors(n_neighbors=k+1, algorithm=\"brute\", metric=metric)\n",
        "    kNN.fit(X)\n",
        "    neighbour = kNN.kneighbors(movie_vec, return_distance=False)\n",
        "    neighbour = neighbour[0][1:]\n",
        "    for n in neighbour:\n",
        "        neighbour_ids.append(movie_inv_mapper[n])\n",
        "    return neighbour_ids\n",
        "\n",
        "recommendation = find_similar_movies(1, X, movie_mapper, movie_inv_mapper, k=10)\n",
        "\n",
        "\n",
        "for i, movie_id in enumerate(recommendation, 1):\n",
        "    print(f\"{i}. {movie_titles[movie_id]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "caiJ5Zdc9KFs",
        "outputId": "ca8ca4ca-4247-485b-e632-f5ffd274bba9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Toy Story 2 (1999)\n",
            "2. Jurassic Park (1993)\n",
            "3. Independence Day (a.k.a. ID4) (1996)\n",
            "4. Star Wars: Episode IV - A New Hope (1977)\n",
            "5. Forrest Gump (1994)\n",
            "6. Lion King, The (1994)\n",
            "7. Star Wars: Episode VI - Return of the Jedi (1983)\n",
            "8. Mission: Impossible (1996)\n",
            "9. Groundhog Day (1993)\n",
            "10. Back to the Future (1985)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install surprise\n",
        "from surprise.model_selection import cross_validate\n",
        "from surprise import SVD\n",
        "from surprise import Dataset\n",
        "from surprise import Reader\n",
        "from surprise.model_selection import train_test_split\n",
        "from surprise import accuracy\n",
        "\n",
        "max_rating = ratings.rating.max()\n",
        "min_rating = ratings.rating.min()\n",
        "\n",
        "reader = Reader(rating_scale=(min_rating, max_rating))\n",
        "data = Dataset.load_from_df(ratings[['userId', 'movieId', 'rating']], reader)\n",
        "algo = SVD()\n",
        "\n",
        "#Cross validation olega na podziale danych na kilka części (zwanych „folds”) w celu sprawdzenia, jak dobrze model będzie generalizował na nowych, niewidzialnych danych\n",
        "cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JMDXgxKE8n_b",
        "outputId": "f73d361f-2585-4754-86d9-bf2a9c735ee4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting surprise\n",
            "  Downloading surprise-0.1-py2.py3-none-any.whl (1.8 kB)\n",
            "Collecting scikit-surprise (from surprise)\n",
            "  Downloading scikit_surprise-1.1.4.tar.gz (154 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.4/154.4 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise->surprise) (1.4.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise->surprise) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise->surprise) (1.11.4)\n",
            "Building wheels for collected packages: scikit-surprise\n",
            "  Building wheel for scikit-surprise (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.4-cp310-cp310-linux_x86_64.whl size=2357240 sha256=a0e829dd8ff7588ec8b7d875a3192a28630ae2daa6b292099e9625e446997932\n",
            "  Stored in directory: /root/.cache/pip/wheels/4b/3f/df/6acbf0a40397d9bf3ff97f582cc22fb9ce66adde75bc71fd54\n",
            "Successfully built scikit-surprise\n",
            "Installing collected packages: scikit-surprise, surprise\n",
            "Successfully installed scikit-surprise-1.1.4 surprise-0.1\n",
            "Evaluating RMSE, MAE of algorithm SVD on 5 split(s).\n",
            "\n",
            "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
            "RMSE (testset)    0.8707  0.8752  0.8659  0.8769  0.8742  0.8726  0.0039  \n",
            "MAE (testset)     0.6684  0.6707  0.6663  0.6731  0.6724  0.6702  0.0025  \n",
            "Fit time          1.49    1.55    1.62    2.38    1.49    1.70    0.34    \n",
            "Test time         0.24    0.13    0.33    0.12    0.23    0.21    0.08    \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'test_rmse': array([0.87068952, 0.87524261, 0.86593923, 0.8768913 , 0.87419967]),\n",
              " 'test_mae': array([0.66843934, 0.67072997, 0.66626442, 0.67305271, 0.67236401]),\n",
              " 'fit_time': (1.489121913909912,\n",
              "  1.5482096672058105,\n",
              "  1.6154491901397705,\n",
              "  2.375845193862915,\n",
              "  1.489720106124878),\n",
              " 'test_time': (0.2436845302581787,\n",
              "  0.12940263748168945,\n",
              "  0.33483052253723145,\n",
              "  0.11871600151062012,\n",
              "  0.2337024211883545)}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "trainset, testset = train_test_split(data, test_size=0.25)\n",
        "\n",
        "algorithm = SVD()\n",
        "\n",
        "algorithm.fit(trainset)\n",
        "predictions = algorithm.test(testset)\n",
        "\n",
        "accuracy.rmse(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BlWo-5vR9qes",
        "outputId": "bced1faf-053a-4ea9-97e6-b9db92424bdd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 0.8695\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8694534408795721"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from surprise.prediction_algorithms import SVD, KNNBasic, KNNBaseline\n",
        "from surprise import Dataset\n",
        "from surprise.model_selection import cross_validate, GridSearchCV\n",
        "from surprise import Reader\n",
        "from surprise import accuracy, Dataset, SVD\n",
        "from surprise.model_selection import train_test_split\n",
        "algorithm = KNNBasic()\n",
        "algorithm.fit(trainset)\n",
        "predict = algorithm.test(testset)\n",
        "accuracy.rmse(predict)\n"
      ],
      "metadata": {
        "id": "uuiw7wtQ5jE_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "832afd67-1b97-43d0-d954-20d5f53ff51d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "RMSE: 0.9459\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9459237129234362"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {\n",
        "    'k': [1, 2, 5, 10, 20, 30, 40, 50]\n",
        "}\n",
        "\n",
        "gs_knn = GridSearchCV(KNNBasic, param_grid, measures=['rmse'], cv=5, n_jobs=-1)\n",
        "gs_knn.fit(data)"
      ],
      "metadata": {
        "id": "JOFGOlggZ-A4"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gs_knn.best_params\n",
        "\n",
        "cross_validate(KNNBasic(), data, measures=['RMSE', 'MAE'], cv=5, verbose=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eHiudd1Lcvdw",
        "outputId": "f96a2fe7-2fdb-4f9c-ad58-6260cb11e5d7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Evaluating RMSE, MAE of algorithm KNNBasic on 5 split(s).\n",
            "\n",
            "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
            "RMSE (testset)    0.9448  0.9458  0.9468  0.9426  0.9554  0.9471  0.0044  \n",
            "MAE (testset)     0.7248  0.7255  0.7251  0.7225  0.7306  0.7257  0.0027  \n",
            "Fit time          0.11    0.13    0.13    0.13    0.13    0.13    0.01    \n",
            "Test time         1.32    1.32    1.48    1.32    1.46    1.38    0.07    \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'test_rmse': array([0.94482931, 0.94583568, 0.94678919, 0.94255682, 0.95542385]),\n",
              " 'test_mae': array([0.72482688, 0.72554744, 0.72506027, 0.72252496, 0.73062406]),\n",
              " 'fit_time': (0.10578632354736328,\n",
              "  0.13210535049438477,\n",
              "  0.13216495513916016,\n",
              "  0.12810754776000977,\n",
              "  0.12741518020629883),\n",
              " 'test_time': (1.319908857345581,\n",
              "  1.3211071491241455,\n",
              "  1.4794209003448486,\n",
              "  1.3214361667633057,\n",
              "  1.464327335357666)}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "algorithm = KNNBaseline()\n",
        "algorithm.fit(trainset)\n",
        "predictions = algorithm.test(testset)\n",
        "accuracy.rmse(predict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hma_rAxGdDj4",
        "outputId": "0580e6ad-c8ec-4488-cfc0-6bb10232819e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estimating biases using als...\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "RMSE: 0.9459\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9459237129234362"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k0T_ZdIcx1cM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}