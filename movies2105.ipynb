{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/UEPP40/PUM/blob/friska_test/movies2105.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TS50DWqd9Qn_",
        "outputId": "391bd3ea-0a0e-4fb2-f153-3f51dc6a9544"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Liczba wszystkich ocen: 100836\n",
            "Liczba filmów w bazie: 9742\n",
            "Liczba użytkowników: 610\n",
            "Średnia liczba ocen na użytkownika: 165.30491803278687\n",
            "Średnia liczba ocen na film: 10.350646684459043\n",
            "\n",
            "Rozkład ocen:\n",
            "rating\n",
            "0.5     1370\n",
            "1.0     2811\n",
            "1.5     1791\n",
            "2.0     7551\n",
            "2.5     5550\n",
            "3.0    20047\n",
            "3.5    13136\n",
            "4.0    26818\n",
            "4.5     8551\n",
            "5.0    13211\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Wczytanie danych o ocenach i filmach\n",
        "ratings = pd.read_csv('https://s3-us-west-2.amazonaws.com/recommender-tutorial/ratings.csv')\n",
        "movies = pd.read_csv('https://s3-us-west-2.amazonaws.com/recommender-tutorial/movies.csv')\n",
        "\n",
        "# Liczba wszystkich ocen\n",
        "total_ratings = ratings.shape[0]\n",
        "\n",
        "# Liczba filmów w bazie\n",
        "total_movies = movies.shape[0]\n",
        "\n",
        "# Liczba użytkowników\n",
        "total_users = ratings['userId'].nunique()\n",
        "\n",
        "# Średnia liczba ocen na użytkownika\n",
        "avg_ratings_per_user = total_ratings / total_users\n",
        "\n",
        "# Średnia liczba ocen na film\n",
        "avg_ratings_per_movie = total_ratings / total_movies\n",
        "\n",
        "# Rozkład ocen\n",
        "ratings_distribution = ratings['rating'].value_counts().sort_index()\n",
        "\n",
        "# Wyświetlenie wyników\n",
        "print(\"Liczba wszystkich ocen:\", total_ratings)\n",
        "print(\"Liczba filmów w bazie:\", total_movies)\n",
        "print(\"Liczba użytkowników:\", total_users)\n",
        "print(\"Średnia liczba ocen na użytkownika:\", avg_ratings_per_user)\n",
        "print(\"Średnia liczba ocen na film:\", avg_ratings_per_movie)\n",
        "print(\"\\nRozkład ocen:\")\n",
        "print(ratings_distribution)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Słownik tytułów filmów\n",
        "movie_titles = dict(zip(movies['movieId'], movies['title']))\n",
        "\n",
        "# Obliczenie C i m\n",
        "C = ratings['rating'].mean()\n",
        "m = ratings.groupby('movieId')['rating'].agg(['count', 'mean'])\n",
        "m = m['count'].mean()\n",
        "\n",
        "# Funkcja bayesian_avg\n",
        "def bayesian_avg(ratings):\n",
        "    bayesian_avg = (C * m + ratings.sum()) / (C + ratings.count())\n",
        "    return bayesian_avg\n",
        "\n",
        "# Obliczenie bayesian_avg_ratings\n",
        "bayesian_avg_ratings = ratings.groupby('movieId')['rating'].agg(bayesian_avg).reset_index()\n",
        "bayesian_avg_ratings.columns = ['movieId', 'bayesian_avg']\n",
        "\n",
        "# Połączenie z danymi o filmach\n",
        "movie_stats = movies.merge(bayesian_avg_ratings, on='movieId')\n",
        "\n",
        "# Wyświetlenie wyników\n",
        "print(movie_stats.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXMg9_68BdYA",
        "outputId": "6872aba7-0e79-44b7-f64d-1d332faff6f9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   movieId                               title  \\\n",
            "0        1                    Toy Story (1995)   \n",
            "1        2                      Jumanji (1995)   \n",
            "2        3             Grumpier Old Men (1995)   \n",
            "3        4            Waiting to Exhale (1995)   \n",
            "4        5  Father of the Bride Part II (1995)   \n",
            "\n",
            "                                        genres  bayesian_avg  \n",
            "0  Adventure|Animation|Children|Comedy|Fantasy      4.024276  \n",
            "1                   Adventure|Children|Fantasy      3.645857  \n",
            "2                               Comedy|Romance      3.708193  \n",
            "3                         Comedy|Drama|Romance      5.028823  \n",
            "4                                       Comedy      3.558189  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "# Wczytanie danych o ocenach i filmach\n",
        "ratings = pd.read_csv('https://s3-us-west-2.amazonaws.com/recommender-tutorial/ratings.csv')\n",
        "movies = pd.read_csv('https://s3-us-west-2.amazonaws.com/recommender-tutorial/movies.csv')\n",
        "\n",
        "# Liczba wszystkich ocen\n",
        "total_ratings = ratings.shape[0]\n",
        "\n",
        "# Liczba filmów w bazie\n",
        "total_movies = movies.shape[0]\n",
        "\n",
        "# Liczba użytkowników\n",
        "total_users = ratings['userId'].nunique()\n",
        "\n",
        "# Średnia liczba ocen na użytkownika\n",
        "avg_ratings_per_user = total_ratings / total_users\n",
        "\n",
        "# Średnia liczba ocen na film\n",
        "avg_ratings_per_movie = total_ratings / total_movies\n",
        "\n",
        "# Rozkład ocen\n",
        "ratings_distribution = ratings['rating'].value_counts().sort_index()\n",
        "\n",
        "# Wyświetlenie wyników\n",
        "print(\"Liczba wszystkich ocen:\", total_ratings)\n",
        "print(\"Liczba filmów w bazie:\", total_movies)\n",
        "print(\"Liczba użytkowników:\", total_users)\n",
        "print(\"Średnia liczba ocen na użytkownika:\", avg_ratings_per_user)\n",
        "print(\"Średnia liczba ocen na film:\", avg_ratings_per_movie)\n",
        "print(\"\\nRozkład ocen:\")\n",
        "print(ratings_distribution)\n",
        "\n",
        "# Słownik tytułów filmów\n",
        "movie_titles = dict(zip(movies['movieId'], movies['title']))\n",
        "\n",
        "# Obliczenie C i m\n",
        "C = ratings['rating'].mean()\n",
        "m = ratings.groupby('movieId')['rating'].agg(['count', 'mean'])\n",
        "m = m['count'].mean()\n",
        "\n",
        "# Funkcja bayesian_avg\n",
        "def bayesian_avg(ratings):\n",
        "    bayesian_avg = (C * m + ratings.sum()) / (C + ratings.count())\n",
        "    return bayesian_avg\n",
        "\n",
        "# Obliczenie bayesian_avg_ratings\n",
        "bayesian_avg_ratings = ratings.groupby('movieId')['rating'].agg(bayesian_avg).reset_index()\n",
        "bayesian_avg_ratings.columns = ['movieId', 'bayesian_avg']\n",
        "\n",
        "# Połączenie z danymi o filmach\n",
        "movie_stats = movies.merge(bayesian_avg_ratings, on='movieId')\n",
        "\n",
        "# Wyświetlenie wyników\n",
        "print(movie_stats.head())\n",
        "\n",
        "def create_sparse(df):\n",
        "    M = df['userId'].nunique()\n",
        "    N = df['movieId'].nunique()\n",
        "    user_mapper = dict(zip(np.unique(df[\"userId\"]), list(range(M))))\n",
        "    movie_mapper = dict(zip(np.unique(df[\"movieId\"]), list(range(N))))\n",
        "    user_inv_mapper = dict(zip(list(range(M)), np.unique(df[\"userId\"])))\n",
        "    movie_inv_mapper = dict(zip(list(range(N)), np.unique(df[\"movieId\"])))\n",
        "    user_index = [user_mapper[i] for i in df['userId']]\n",
        "    item_index = [movie_mapper[i] for i in df['movieId']]\n",
        "    X = csr_matrix((df[\"rating\"], (user_index, item_index)), shape=(M,N))\n",
        "    return X, user_mapper, movie_mapper, user_inv_mapper, movie_inv_mapper\n",
        "\n",
        "# Utworzenie macierzy rzadkiej\n",
        "X, user_mapper, movie_mapper, user_inv_mapper, movie_inv_mapper = create_sparse(ratings)\n",
        "\n",
        "n_total = X.shape[0] * X.shape[1]\n",
        "n_ratings = X.nnz\n",
        "sparsity = n_ratings / n_total\n",
        "sparsity_p = round(sparsity * 100, 2)\n",
        "\n",
        "print(f\"Matrix sparsity: {sparsity_p}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-T_YXCTyDBgy",
        "outputId": "4fcc65d6-f066-4f6c-a8ed-38cf34177577"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Liczba wszystkich ocen: 100836\n",
            "Liczba filmów w bazie: 9742\n",
            "Liczba użytkowników: 610\n",
            "Średnia liczba ocen na użytkownika: 165.30491803278687\n",
            "Średnia liczba ocen na film: 10.350646684459043\n",
            "\n",
            "Rozkład ocen:\n",
            "rating\n",
            "0.5     1370\n",
            "1.0     2811\n",
            "1.5     1791\n",
            "2.0     7551\n",
            "2.5     5550\n",
            "3.0    20047\n",
            "3.5    13136\n",
            "4.0    26818\n",
            "4.5     8551\n",
            "5.0    13211\n",
            "Name: count, dtype: int64\n",
            "   movieId                               title  \\\n",
            "0        1                    Toy Story (1995)   \n",
            "1        2                      Jumanji (1995)   \n",
            "2        3             Grumpier Old Men (1995)   \n",
            "3        4            Waiting to Exhale (1995)   \n",
            "4        5  Father of the Bride Part II (1995)   \n",
            "\n",
            "                                        genres  bayesian_avg  \n",
            "0  Adventure|Animation|Children|Comedy|Fantasy      4.024276  \n",
            "1                   Adventure|Children|Fantasy      3.645857  \n",
            "2                               Comedy|Romance      3.708193  \n",
            "3                         Comedy|Drama|Romance      5.028823  \n",
            "4                                       Comedy      3.558189  \n",
            "Matrix sparsity: 1.7%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import NearestNeighbors\n",
        "import numpy as np\n",
        "\n",
        "def find_similar_movies(movie_id, X, movie_mapper, movie_inv_mapper, k, metric='cosine'):\n",
        "    X = X.T\n",
        "    neighbour_ids = []\n",
        "    movie_ind = movie_mapper[movie_id]\n",
        "    movie_vec = X[movie_ind]\n",
        "    if isinstance(movie_vec, (np.ndarray)):\n",
        "        movie_vec = movie_vec.reshape(1, -1)\n",
        "    kNN = NearestNeighbors(n_neighbors=k+1, algorithm=\"brute\", metric=metric)\n",
        "    kNN.fit(X)\n",
        "    neighbour = kNN.kneighbors(movie_vec, return_distance=False)\n",
        "    neighbour = neighbour[0][1:]  # Pomijamy pierwszy element, który jest samym filmem\n",
        "    for n in neighbour:\n",
        "        neighbour_ids.append(movie_inv_mapper[n])\n",
        "    return neighbour_ids\n",
        "\n",
        "# Przykładowe użycie funkcji do znalezienia 10 rekomendacji dla filmu o identyfikatorze 1 (Toy Story)\n",
        "recommendations = find_similar_movies(1, X, movie_mapper, movie_inv_mapper, k=10)\n",
        "\n",
        "# Wyświetlenie rekomendacji\n",
        "for i, movie_id in enumerate(recommendations, 1):\n",
        "    print(f\"{i}. {movie_titles[movie_id]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "soMNMJXoG_3g",
        "outputId": "c7df5262-54f6-488a-f4e5-78e9bbf83c60"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Toy Story 2 (1999)\n",
            "2. Jurassic Park (1993)\n",
            "3. Independence Day (a.k.a. ID4) (1996)\n",
            "4. Star Wars: Episode IV - A New Hope (1977)\n",
            "5. Forrest Gump (1994)\n",
            "6. Lion King, The (1994)\n",
            "7. Star Wars: Episode VI - Return of the Jedi (1983)\n",
            "8. Mission: Impossible (1996)\n",
            "9. Groundhog Day (1993)\n",
            "10. Back to the Future (1985)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install surprise library\n",
        "!pip install surprise\n",
        "\n",
        "# Importing relevant libraries\n",
        "from surprise.model_selection import cross_validate\n",
        "from surprise import SVD\n",
        "from surprise import Dataset\n",
        "from surprise import Reader\n",
        "from surprise.model_selection import train_test_split\n",
        "from surprise import accuracy\n",
        "\n",
        "# Assuming 'ratings' DataFrame is already loaded\n",
        "# Get minimum and maximum rating from the dataset\n",
        "min_rating = ratings.rating.min()\n",
        "max_rating = ratings.rating.max()\n",
        "reader = Reader(rating_scale=(min_rating, max_rating))\n",
        "data = Dataset.load_from_df(ratings[['userId', 'movieId', 'rating']], reader)\n",
        "\n",
        "# Define the algorithm\n",
        "algo = SVD()\n",
        "\n",
        "# Perform cross-validation\n",
        "cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQb_5-Qmy0BM",
        "outputId": "ae255fda-2453-4652-c1d4-35fecc341699"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting surprise\n",
            "  Downloading surprise-0.1-py2.py3-none-any.whl (1.8 kB)\n",
            "Collecting scikit-surprise (from surprise)\n",
            "  Downloading scikit_surprise-1.1.4.tar.gz (154 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.4/154.4 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise->surprise) (1.4.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise->surprise) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise->surprise) (1.11.4)\n",
            "Building wheels for collected packages: scikit-surprise\n",
            "  Building wheel for scikit-surprise (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.4-cp310-cp310-linux_x86_64.whl size=2357257 sha256=adb8631157b31cfae6f56086cd4bc0ee0b21372c71587c26572fb68a07a861a2\n",
            "  Stored in directory: /root/.cache/pip/wheels/4b/3f/df/6acbf0a40397d9bf3ff97f582cc22fb9ce66adde75bc71fd54\n",
            "Successfully built scikit-surprise\n",
            "Installing collected packages: scikit-surprise, surprise\n",
            "Successfully installed scikit-surprise-1.1.4 surprise-0.1\n",
            "Evaluating RMSE, MAE of algorithm SVD on 5 split(s).\n",
            "\n",
            "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
            "RMSE (testset)    0.8748  0.8767  0.8787  0.8707  0.8695  0.8741  0.0035  \n",
            "MAE (testset)     0.6708  0.6728  0.6744  0.6702  0.6693  0.6715  0.0018  \n",
            "Fit time          1.65    1.63    1.89    2.23    1.64    1.81    0.23    \n",
            "Test time         0.28    0.14    0.35    0.14    0.25    0.23    0.08    \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'test_rmse': array([0.87484521, 0.87665724, 0.87867681, 0.87072118, 0.8694975 ]),\n",
              " 'test_mae': array([0.67080424, 0.6728014 , 0.67437825, 0.67020174, 0.66927629]),\n",
              " 'fit_time': (1.6463375091552734,\n",
              "  1.6271719932556152,\n",
              "  1.8852250576019287,\n",
              "  2.230910539627075,\n",
              "  1.6404986381530762),\n",
              " 'test_time': (0.2803940773010254,\n",
              "  0.14051151275634766,\n",
              "  0.3480336666107178,\n",
              "  0.1439213752746582,\n",
              "  0.2472834587097168)}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# sample random trainset and testset\n",
        "# test set is made of 25% of the ratings.\n",
        "trainset, testset = train_test_split(data, test_size=0.25)\n",
        "\n",
        "algo = SVD()\n",
        "\n",
        "# Train the algorithm on the trainset, and predict ratings for the testset\n",
        "algo.fit(trainset)\n",
        "predictions = algo.test(testset)\n",
        "\n",
        "# Then compute RMSE\n",
        "accuracy.rmse(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-bkLgto719CL",
        "outputId": "f85f93cb-94e4-45a4-c88f-13c16def91eb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 0.8703\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8703286274853377"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "\n",
        "import sklearn.model_selection\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import KFold # StratifiedKFold, RepeatedKFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4NmPftgE_HhR",
        "outputId": "c5538542-7748-4701-c830-f6e9626de90f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create dataset\n",
        "X, y = make_classification(n_samples=100, n_features=20, n_informative=15, n_redundant=5, random_state=1) # prepare the cross-validation procedure\n",
        "cv = KFold(n_splits=10, random_state=1, shuffle=True)"
      ],
      "metadata": {
        "id": "z6l3Urbt_H9b"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier"
      ],
      "metadata": {
        "id": "CtyONoYg_L7D"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Utworzenie modelu drzewa decyzyjnego\n",
        "model = DecisionTreeClassifier()\n",
        "\n",
        "# Ocena modelu przy użyciu walidacji krzyżowej\n",
        "scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "\n",
        "# Wyświetlenie wyników\n",
        "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ho4WeRcfAIsb",
        "outputId": "068becd6-52d3-4f1e-fdb6-3199bdd2c7a2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.670 (0.119)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JYLeVoE6ANKk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}